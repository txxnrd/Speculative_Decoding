# Affine Alignment based Draft Tree Search for Speculative Decoding

ì´ í”„ë¡œì íŠ¸ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì¶”ë¡  ì†ë„ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ í˜ì‹ ì ì¸ speculative decoding ê¸°ë²•ì„ êµ¬í˜„í•©ë‹ˆë‹¤.

## ğŸ“‹ ì£¼ìš” íŠ¹ì§•

1. **Multi-candidate Tree Search**: Draft ëª¨ë¸ì´ íŠ¸ë¦¬ êµ¬ì¡°ë¡œ ì—¬ëŸ¬ í† í° ê²½ë¡œë¥¼ ìƒì„±
2. **Affine Alignment**: Draft hidden stateë¥¼ Target hidden stateë¡œ íš¨ìœ¨ì ìœ¼ë¡œ ë³€í™˜
3. **Acceptance Probability Prediction**: MLP ê¸°ë°˜ìœ¼ë¡œ íƒ€ê²Ÿ ëª¨ë¸ì˜ ê²€ì¦ í†µê³¼ í™•ë¥  ì˜ˆì¸¡
4. **Intelligent Tree Pruning**: ë‚®ì€ í™•ë¥  ê²½ë¡œë¥¼ ì‚¬ì „ì— ì œê±°í•˜ì—¬ ê²€ì¦ ì˜¤ë²„í—¤ë“œ ìµœì†Œí™”
5. **Adaptive Optimization**: ì‹¤ì‹œê°„ ì„±ëŠ¥ì— ë”°ë¼ pruning ì „ëµ ë™ì  ì¡°ì •

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### ì„¤ì¹˜

```bash
# Clone repository
git clone https://github.com/yourusername/speculative-decoding.git
cd speculative-decoding

# Install dependencies
pip install -r requirements.txt
```

### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from speculative_decoder import SpeculativeDecoder
from config import SpeculativeDecodingConfig

# Configuration
config = SpeculativeDecodingConfig()
config.model.draft_model_name = "meta-llama/Llama-3.1-8B"
config.model.target_model_name = "meta-llama/Llama-3.1-70B"

# Initialize decoder
decoder = SpeculativeDecoder(config)

# Generate text
prompt = "The future of AI is"
input_ids = decoder.tokenizer.encode(prompt, return_tensors="pt")
generated_ids, stats = decoder.generate(input_ids, max_new_tokens=100)

# Decode output
generated_text = decoder.tokenizer.decode(generated_ids[0])
print(generated_text)
```

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

### í•µì‹¬ êµ¬ì„± ìš”ì†Œ

1. **AffineAlignment** (`models/affine_alignment.py`)
   - Draft ëª¨ë¸ì˜ hidden stateë¥¼ Target ëª¨ë¸ì˜ hidden stateë¡œ ë³€í™˜
   - ìˆ˜ì‹: `h_target = W * h_draft + b`
   - í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì €ì¥/ë¡œë“œ ì§€ì›

2. **DraftTreeSearch** (`models/draft_tree_search.py`)
   - Multi-candidate í† í° ìƒì„±
   - Tree êµ¬ì¡° ê´€ë¦¬ ë° íƒìƒ‰
   - Top-k, Top-p sampling ì§€ì›

3. **AcceptanceProbabilityPredictor** (`models/acceptance_predictor.py`)
   - MLP ê¸°ë°˜ í™•ë¥  ì˜ˆì¸¡
   - Temperature calibration
   - Confidence ë¶„ì„

4. **TreePruner** (`models/tree_pruner.py`)
   - Threshold ê¸°ë°˜ pruning
   - Adaptive pruning ì „ëµ
   - Level-wise pruning ì§€ì›

## ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹

### ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰

```bash
cd tests
python benchmark.py
```

### ì£¼ìš” ë©”íŠ¸ë¦­

- **Acceptance Rate**: Draft í† í°ì´ Target ëª¨ë¸ì— ì˜í•´ ìˆ˜ë½ë˜ëŠ” ë¹„ìœ¨
- **Speedup**: í‘œì¤€ ìƒì„± ëŒ€ë¹„ ì†ë„ í–¥ìƒ ë°°ìˆ˜
- **Pruning Effectiveness**: ì œê±°ëœ ê²½ë¡œ ë¹„ìœ¨ vs ì„±ëŠ¥ ì˜í–¥
- **Latency Breakdown**: ê° ì»´í¬ë„ŒíŠ¸ë³„ ì‹œê°„ ë¶„ì„

## ğŸ”§ ê³ ê¸‰ ì„¤ì •

### Tree Search íŒŒë¼ë¯¸í„°

```python
config.tree_search.max_candidates = 5  # ê° ë…¸ë“œì˜ ìµœëŒ€ í›„ë³´ ìˆ˜
config.tree_search.max_depth = 4      # Tree ìµœëŒ€ ê¹Šì´
config.tree_search.temperature = 0.8   # Sampling temperature
```

### Pruning ì„¤ì •

```python
config.pruning.min_acceptance_prob = 0.1  # ìµœì†Œ acceptance í™•ë¥ 
config.pruning.adaptive_pruning = True    # ì ì‘ì  pruning ì‚¬ìš©
config.pruning.pruning_ratio = 0.5       # ëª©í‘œ pruning ë¹„ìœ¨
```

### Affine Alignment

```python
# ì‚¬ì „ í•™ìŠµëœ alignment ê°€ì¤‘ì¹˜ ë¡œë“œ
config.affine_alignment.alignment_checkpoint = "path/to/checkpoint.pt"
```

## ğŸ“ˆ ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ

- **Llama 3.1 8B â†’ 70B**: 2-3x speedup (task dependent)
- **Acceptance Rate**: 40-60% (with proper alignment)
- **Memory Overhead**: ~10% additional for alignment/prediction modules

## ğŸ¤ ê¸°ì—¬ ë°©ë²•

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

## ğŸ”— ì°¸ê³  ìë£Œ

- [Speculative Decoding Paper](https://arxiv.org/abs/2211.17192)
- [Multi-candidate Speculative Decoding](https://arxiv.org/abs/2401.06706)
- [Llama 3.1 Model Card](https://github.com/facebookresearch/llama)

## ğŸ“§ ì—°ë½ì²˜

ì§ˆë¬¸ì´ë‚˜ ì œì•ˆì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì´ìŠˆë¥¼ ì—´ì–´ì£¼ì„¸ìš”! 